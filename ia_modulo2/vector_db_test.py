"""
==============================================================
Armazenamento e Busca Sem칙ntica com ChromaDB
--------------------------------------------------------------
Este script demonstra como criar uma base vetorial local com
ChromaDB, inserir embeddings e realizar consultas sem칙nticas.
==============================================================
"""

# ============================================================
#  IMPORTA칂칏ES
# ============================================================

import chromadb
from openai import OpenAI
from dotenv import load_dotenv
import os
import numpy as np

# ============================================================
#  CONFIGURA칂츾O DE CLIENTES
# ============================================================

# Carrega vari치veis de ambiente (.env)
load_dotenv()

# Inicializa cliente da OpenAI
client_openai = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Inicializa cliente do ChromaDB (modo persistente)
client_chroma = chromadb.PersistentClient(path="./chroma_db")

# ============================================================
#  CRIA칂츾O OU ACESSO  COLE칂츾O
# ============================================================

collection = client_chroma.get_or_create_collection(
    name="meus_textos",
    metadata={
        "descricao": "Exemplo de cole칞칚o de textos sem칙nticos",
        "hnsw:space": "cosine",       
    },
    embedding_function=None # N칚o usa o modelo iterno do chroma, vamos utilizar da openAI
)

# ============================================================
#  INSER칂츾O DE DADOS (TEXTOS E EMBEDDINGS)
# ============================================================

# Textos de exemplo
textos = [
    "Um cachorro brincando na grama",
    "Um carro esportivo acelerando na pista",
    "Um gato dormindo no sof치",
    "Um atleta correndo na praia"
]

# Gera embeddings para cada texto usando o modelo da OpenAI
resposta = client_openai.embeddings.create(
    model="text-embedding-3-small",
    input=textos
)

# Extrai os vetores (embeddings)
embeddings = [np.array(item.embedding) for item in resposta.data]

# Adiciona tudo  cole칞칚o
collection.add(
    ids=[f"id_{i}" for i in range(len(textos))],
    documents=textos,
    embeddings=embeddings,
    metadatas=[{"origem": "exemplo"} for _ in textos]
)

# ============================================================
#  CONSULTA SEM츽NTICA
# ============================================================

consulta = "animal descansando"
print(f"\n游댌 Consulta: {consulta}\n")

# Gera embedding da consulta usando o mesmo modelo
consulta_embedding = client_openai.embeddings.create(
    model="text-embedding-3-small",
    input=[consulta]
).data[0].embedding

# Faz a busca usando o embedding gerado
resultado = collection.query(
    query_embeddings=[consulta_embedding],
    n_results=2
)

# Exibe os resultados 
for doc, dist in zip(resultado["documents"][0], resultado["distances"][0]): 
    print(f"Texto encontrado: {doc}") 
    print(f"Dist칙ncia sem칙ntica: {dist:.4f}\n") 
